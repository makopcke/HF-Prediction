{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "069b5887",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "069b5887",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a75a98671f121a252e9074ae86f876e5",
          "grade": false,
          "grade_id": "cell-e744ed1b5809a6fb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# **DL4H598 Final Project**\n",
        "# Project Team #44 - Miles Kopcke and Sergio Rio\n",
        "# {mkopcke2, sav7}@illinois.edu\n",
        "# Paper ID #12 - [\"Using recurrent neural network models for early detection of heart failure onset\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/)\n",
        "# Edward Choi, Andy Schuetz, Walter F Stewart, and Jimeng Sun\n",
        "\n",
        "## Overview\n",
        "## The scope of this project is to reproduce the main  results claimed by the authors to be “state-of-the-art prediction performance,” outperforming traditional machine learning models. We will run experiments with the two GRU models (with and without time duration information) and the MLP model described in the research paper for all three types of inputs (one-hot encoding, grouped codes, and medical concept vectors based on Skip-gram). \n",
        "## The original study used data from Sutter Palo Alto Medical Foundation (Sutter-PAMF) primary care patients from May 16, 2000, to May 23, 2023. This data was used to construct 3,884 Heart Failure cases and 28,903 controls. Currently, we’re pursuing the use of the IBM MarketScan Research Database (Merative n.d.) as one of our team members works for IBM Watson Health (now called Merative). This would allow us to have a very similar patient population to the original study.\n",
        "\n",
        "####  *Choi, Edward, Andy Schuetz, Walter F Stuart, and Jimeng Sun. 2016. \"Using recurrent neural network models for early detection of heart failure onset.\" Journal of the American Medical Informatics Association 24 (2): 361-369. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X-KbgqrK2WSV",
      "metadata": {
        "id": "X-KbgqrK2WSV"
      },
      "source": [
        "## **1. Data preparation**\n",
        "## Develop, test, and execute programs for dataset sampling of cases and controls, engineer data into the three types of encoding (one-hot encoding, grouped codes, and medical concept vectors based on Skip-gram), and iteratively divide the data into train, validation, and test with a ratio of 5:1:1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We’re using the IBM MarketScan Research Database (Merative n.d.). \n",
        "## This allows us to have a very similar patient population to the original study. Specifically, we’d be using the years 2011 to 2013, composed of 66,020,609 patients in the outpatient setting with a total of 3,120,102,668 encounters, giving us an average number of 47 encounters per patient. We adopted the same density sampling design used for the longitudinal records of the research paper  (Choi, et al. 2016), section Definitions of cases and controls to ensure we obtain a similar data sample.\n",
        "## MarketScan data was extracted from a Snowflake datalake, exported to csv files and processed in Python using Pandas library. \n",
        "## Plese check Market_Scan_Data_Extraction.sql file in https://github.com/svianrio/HF-Prediction/\n"
      ],
      "metadata": {
        "id": "8D5g4WYjaUSm"
      },
      "id": "8D5g4WYjaUSm"
    },
    {
      "cell_type": "markdown",
      "id": "2257e3d5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2257e3d5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "14f613d1aec75d3a025c8b5ad6e5d9a4",
          "grade": false,
          "grade_id": "cell-c4713a38b23a9a65",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Using small dataset to train and test models\n",
        "\n",
        "We will use a dataset synthesized from [MIMIC-III](https://mimic.physionet.org/gettingstarted/access/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ed22fb",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "39ed22fb",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "787ef941c7a0aeb12e4e01694dd345b8",
          "grade": false,
          "grade_id": "cell-8a60df0209e82e03",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pdb\n",
        "import sys\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "\n",
        "# set random seed for reproducibility\n",
        "# “the Ultimate Question of Life, the Universe, and Everything”\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "# torch.use_deterministic_algorithms(True)\n",
        "os.environ['PYTHONASHSEED'] = str(seed)\n",
        "\n",
        "# define data set path\n",
        "DATA_PATH = '/Users/mkopcke/Documents/cs598'\n",
        "\n",
        "# define number of timesteps to be used for model development\n",
        "global timesteps\n",
        "timesteps = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886d4b9c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "886d4b9c",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab7e0a5351f10adcbfc6899165cf22e7",
          "grade": false,
          "grade_id": "cell-561a0cb8fbdb04b6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "102cecbb-969c-4c0b-bdb4-cc37950646c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54154\n",
            "54154\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[19, 8693, 46],\n",
              " [467, 8693],\n",
              " [9900, 492, 241, 822, 9015],\n",
              " [202, 83, 15398, 8695],\n",
              " [83, 621, 846, 8695],\n",
              " [9729, 19, 15350, 15551],\n",
              " [15350, 15551],\n",
              " [865, 83, 19, 9395, 8695],\n",
              " [15350, 15551]]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hfs = pd.read_csv('input_hfs.csv')[\"Y\"].tolist()\n",
        "\n",
        "seqs = pickle.load(open(os.path.join(DATA_PATH,'input_seqs.pkl'), 'rb'))\n",
        "\n",
        "print(len(hfs))\n",
        "print(len(seqs))\n",
        "seqs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MBgg9IUXVJVq",
      "metadata": {
        "id": "MBgg9IUXVJVq"
      },
      "outputs": [],
      "source": [
        "# define maxium number of codes\n",
        "global MAX_CODES\n",
        "# MAX_CODES = len(types)\n",
        "MAX_CODES = 18945"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace72679",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ace72679",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f988f259a45551a299afe790b2f6b712",
          "grade": false,
          "grade_id": "cell-6040b080dbe251f4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Dataloader Class\n",
        "\n",
        "We will use the sequences of diagnosis codes `seqs` as input and heart failure `hfs` as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7fb9129",
      "metadata": {
        "deletable": false,
        "id": "a7fb9129"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, seqs, hfs):\n",
        "\n",
        "        self.x = seqs\n",
        "        self.y = hfs\n",
        "    \n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        return self.x[index], self.y[index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_u6FMNEG4FqF",
      "metadata": {
        "id": "_u6FMNEG4FqF"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(seqs, hfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5E6LuMu2Bwa5",
      "metadata": {
        "id": "5E6LuMu2Bwa5"
      },
      "outputs": [],
      "source": [
        "def load_data(train_dataset, val_dataset, batch_size,collate_fn):\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size, collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b549ec",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "47b549ec",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2c5ce67b8f3ecc659633ff06f955199b",
          "grade": false,
          "grade_id": "cell-01c84d91d41635bc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "##  Data Collator for multi-hot vectors\n",
        "\n",
        "For example, when the `DataLoader` gets a list of two samples.\n",
        "\n",
        "```\n",
        "[ [ [0, 1, 2], [3, 0] ], \n",
        "  [ [1, 3, 6, 3], [2], [3, 1] ] ]\n",
        "```\n",
        "\n",
        "where the first sample has two visits `[0, 1, 2]` and `[3, 0]` and the second sample has three visits `[1, 3, 6, 3]`, `[2]`, and `[3, 1]`.\n",
        "\n",
        "The collate function `Collator()` is supposed to concatenate all visits of one patient together to form the inputs, as\n",
        "\n",
        "```\n",
        "[[0, 1, 2, 3 ,0],\n",
        " [1, 3, 6, 3, 2, 3 ,1]]\n",
        "\n",
        "```\n",
        "\n",
        "Further, we transform this to a multi-hot vector representing the appearances of events. Suppose we the number of all possible events is 6, the yielded outputs should be\n",
        "\n",
        "```\n",
        "[[0, 1, 1, 1, 0, 0],\n",
        " [0, 1, 1, 0, 0, 1]]\n",
        "```\n",
        "which will be the final inputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e688ba65",
      "metadata": {
        "deletable": false,
        "id": "e688ba65"
      },
      "outputs": [],
      "source": [
        "class MultiHotCollator:\n",
        "    def __init__(self, total_number_of_codes):\n",
        "        self.max_num_codes = total_number_of_codes\n",
        "        \n",
        "    def __call__(self, data):\n",
        "        \n",
        "        sequences, labels = zip(*data)\n",
        "        num_patients = len(sequences)\n",
        "        num_visits = [len(patient) for patient in sequences]\n",
        "        num_codes = [len(visit) for patient in sequences for visit in patient]\n",
        "\n",
        "        max_num_visits = max(num_visits)\n",
        "        max_num_codes = self.max_num_codes\n",
        "        \n",
        "        y = torch.tensor(labels, dtype=torch.float)\n",
        "        x = torch.zeros((num_patients, timesteps, max_num_codes), dtype=torch.float)\n",
        "        masks = torch.zeros((num_patients, timesteps,1), dtype=torch.float)\n",
        "        \n",
        "        for i_patient, patient in enumerate(sequences):\n",
        "            y[i_patient] = labels[i_patient]\n",
        "            \n",
        "            for visit_number, visit in enumerate(patient):\n",
        "              \n",
        "              if visit_number < timesteps: \n",
        "                idx = torch.tensor([visit], dtype=torch.int64)\n",
        "                multihot = torch.zeros((1,max_num_codes), dtype=torch.float)\n",
        "                x[i_patient, visit_number,:] = multihot.scatter_(dim=1, index=idx, src=torch.ones((idx.size(0),idx.size(1)),dtype=torch.float))\n",
        "                masks[i_patient, visit_number] = 1\n",
        "            \n",
        "                \n",
        "        return x, masks, y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W3ZWZ3Tt4q-0",
      "metadata": {
        "id": "W3ZWZ3Tt4q-0"
      },
      "outputs": [],
      "source": [
        "collate_fn = MultiHotCollator(MAX_CODES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tkBFe1tzO7XW",
      "metadata": {
        "id": "tkBFe1tzO7XW"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(seqs, hfs)\n",
        "a,b=dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "210e62a3",
      "metadata": {
        "id": "210e62a3"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(seqs, hfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "retuFaePwKrR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "retuFaePwKrR",
        "outputId": "ff4c6cbf-f9c8-436e-b0b6-3e6157263fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 800\n",
            "Length of val dataset: 200\n"
          ]
        }
      ],
      "source": [
        "split = int(len(dataset)*0.8)\n",
        "\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, val_dataset = random_split(dataset, lengths)\n",
        "\n",
        "print(\"Length of train dataset:\", len(train_dataset))\n",
        "print(\"Length of val dataset:\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bCBoswKPkdQw",
      "metadata": {
        "id": "bCBoswKPkdQw"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader = load_data(train_dataset, val_dataset, batch_size=10, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "drcnQy_K7_xr",
      "metadata": {
        "id": "drcnQy_K7_xr"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader, val_loader = load_data(train_dataset, val_dataset, batch_size, collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xmj8WFmo8dWc",
      "metadata": {
        "id": "xmj8WFmo8dWc"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(seqs, hfs)\n",
        "collate_fn = MultiHotCollator(MAX_CODES)\n",
        "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn, shuffle=False)\n",
        "loader_iter = iter(loader)\n",
        "c, m, d = next(loader_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dGNH7CaNToHH",
      "metadata": {
        "id": "dGNH7CaNToHH"
      },
      "source": [
        "##  Data Collator for Embeddings - Padding and Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vu4jOLRXZZBv",
      "metadata": {
        "id": "vu4jOLRXZZBv"
      },
      "outputs": [],
      "source": [
        "def PadMaskCollator(data):\n",
        "\n",
        "    sequences, labels = zip(*data)\n",
        "\n",
        "    y = torch.tensor(labels, dtype=torch.float)\n",
        "    \n",
        "    num_patients = len(sequences)\n",
        "    num_visits = [len(patient) for patient in sequences]\n",
        "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
        "\n",
        "    max_num_visits = max(num_visits)\n",
        "    max_num_codes = max(num_codes)\n",
        "    \n",
        "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
        "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
        "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
        "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
        "    for i_patient, patient in enumerate(sequences):\n",
        "        last_visit = 0\n",
        "        for j_visit, visit in enumerate(patient):\n",
        "            a_codes = 0\n",
        "            for k_code, code in enumerate(visit):\n",
        "                x[i_patient,j_visit,k_code] = code\n",
        "                masks[i_patient,j_visit,k_code] = True\n",
        "                a_codes = k_code\n",
        "                last_visit = j_visit\n",
        "    \n",
        "    return x, masks, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GCAVkztZGPJE",
      "metadata": {
        "id": "GCAVkztZGPJE"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(seqs, hfs)\n",
        "loader = DataLoader(dataset, batch_size=32, collate_fn=PadMaskCollator)\n",
        "loader_iter = iter(loader)\n",
        "x, masks, y = next(loader_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HR1sau_BGYHp",
      "metadata": {
        "id": "HR1sau_BGYHp"
      },
      "outputs": [],
      "source": [
        "def sum_embeddings_with_mask(x, masks):\n",
        "\n",
        "    samples = x.size(0)\n",
        "    visits = x.size(1)\n",
        "    diag_codes = x.size(2)\n",
        "    emb_dim = x.size(3)\n",
        "    sum_embeddings = torch.zeros((samples,visits, emb_dim), dtype=torch.long)\n",
        "    masks = torch.unsqueeze(masks,3)\n",
        "    x = x * masks.expand([samples, visits, diag_codes, emb_dim])\n",
        "\n",
        "    return torch.sum(x,2,keepdim=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aEotG7zYG0es",
      "metadata": {
        "id": "aEotG7zYG0es"
      },
      "outputs": [],
      "source": [
        "def get_last_visit(hidden_states, masks):\n",
        "\n",
        "    batch_size = hidden_states.size(0)\n",
        "    len_true_visit = masks.sum(dim = 2)\n",
        "    nz = len_true_visit.count_nonzero(dim=1)\n",
        "\n",
        "    return hidden_states[range(0,batch_size),nz-1,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kdBIzfnVTyY7",
      "metadata": {
        "id": "kdBIzfnVTyY7"
      },
      "source": [
        "##  Data Collator Aggregator - Required for MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G2KJvKMwT78D",
      "metadata": {
        "id": "G2KJvKMwT78D"
      },
      "outputs": [],
      "source": [
        "def Aggregator(data):\n",
        "\n",
        "    sequences, labels = zip(*data)\n",
        "\n",
        "    y = torch.tensor(labels, dtype=torch.float)\n",
        "    \n",
        "    num_patients = len(sequences)\n",
        "    num_visits = [len(patient) for patient in sequences]\n",
        "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
        "\n",
        "    max_num_visits = max(num_visits)\n",
        "    max_num_codes = max(num_codes)\n",
        "    \n",
        "    x = torch.zeros((num_patients, MAX_CODES), dtype=torch.float)\n",
        "\n",
        "    for i_patient, patient in enumerate(sequences):\n",
        "        for j_visit, visit in enumerate(patient):\n",
        "            for k_code, code in enumerate(visit):\n",
        "                x[i_patient, code] += 1\n",
        "    \n",
        "    m = torch.mean(x)\n",
        "    x = (x - m) / x.max()\n",
        "    \n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w96dgrAlV256",
      "metadata": {
        "id": "w96dgrAlV256"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(seqs, hfs)\n",
        "loader = DataLoader(dataset, batch_size=32, collate_fn=Aggregator)\n",
        "loader_iter = iter(loader)\n",
        "x, y = next(loader_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xmXBm1hsZI3N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmXBm1hsZI3N",
        "outputId": "48c60ce0-c43b-4f55-d42f-78a7665b72a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 18945])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QDW29CL6824q",
      "metadata": {
        "id": "QDW29CL6824q"
      },
      "source": [
        "## **2. Model development**\n",
        "## Iteratively develop and test models, starting with MLP, GRU without duration information, and finally, GRU with duration information for all input types.\n",
        "\n",
        "###  **Models with their corresponding hyper-parameters**\n",
        "### **MLP with one-hot vectors -** L2 regularization: 0.01, Hidden layer size: 15, Max epoch: 100\n",
        "### **MLP with grouped code vectors & medical concept vectors -** L2 regularization: 0.001, Hidden layer size: 100, Max epoch: 100\n",
        "### **All GRU models -** L2 regularization: 0.001, Hidden layer size: 100, Max epoch: 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zqyMhBPe3pUg",
      "metadata": {
        "id": "zqyMhBPe3pUg"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, num_units):\n",
        "        \"\"\"\n",
        "        MLP \n",
        "        layer1 with num_codes units\n",
        "        layer2 with 15 units\n",
        "             \n",
        "        \"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_units,15)\n",
        "        self.fc2 = nn.Linear(15,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "\n",
        "    batch_size = x.shape[0]\n",
        "    x = self.fc1(x)\n",
        "    logits = self.fc2(x)        \n",
        "    probs = self.sigmoid(logits)\n",
        "    return probs.view(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yn1BHZIkxsNN",
      "metadata": {
        "id": "Yn1BHZIkxsNN"
      },
      "outputs": [],
      "source": [
        "class GRU(nn.Module):\n",
        "  def __init__(self, num_codes,dp_out=0):\n",
        "        \"\"\"\n",
        "        RNN with 1 layer and 100 GRU units\n",
        "        \"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        # self.embedding = nn.Embedding(num_codes,timesteps)\n",
        "        self.gru = nn.GRU(input_size = MAX_CODES, hidden_size= timesteps, num_layers = 1, bias=True, batch_first=True)\n",
        "        if dp_out > 0:\n",
        "          self.dropout = nn.Dropout(dp_out)\n",
        "          self.dpout = True\n",
        "        else:\n",
        "          self.dpout = False\n",
        "        self.fc = nn.Linear(timesteps,1,bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x, masks):\n",
        "\n",
        "    batch_size = x.shape[0]\n",
        "    # x = self.embedding(x)\n",
        "    # x = sum_embeddings_with_mask(x, masks)\n",
        "\n",
        "    # We only care about the last status of the hidden layer\n",
        "    output, h_n = self.gru(x)\n",
        "    true_h_n = get_last_visit(output, masks)\n",
        "    if self.dpout:\n",
        "      true_h_n = self.dropout(true_h_n)\n",
        "    logits = self.fc(true_h_n)        \n",
        "    probs = self.sigmoid(logits)\n",
        "\n",
        "    return probs.view(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yyhHmpJs9D5B",
      "metadata": {
        "id": "yyhHmpJs9D5B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9l8F2Bt19IEk",
      "metadata": {
        "id": "9l8F2Bt19IEk"
      },
      "source": [
        "## **3. Performance Evaluation**\n",
        "## Evaluate AUC scores of developed models and measure inference times for a single patient. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KL8oXdmK0zmd",
      "metadata": {
        "id": "KL8oXdmK0zmd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "def eval_model_with_mask(model, val_loader):\n",
        "    \n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    y_pred = torch.LongTensor()\n",
        "    y_score = torch.Tensor()\n",
        "    y_true = torch.LongTensor()\n",
        "    model.eval()\n",
        "    for x, masks, y in val_loader:\n",
        "        y_hat = model(x, masks)\n",
        "        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
        "        y_hat = (y_hat > 0.5).int()\n",
        "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
        "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
        "\n",
        "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "    roc_auc = roc_auc_score(y_true, y_score, average='samples')\n",
        "\n",
        "    return p, r, f, roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ICyueLRaVhl",
      "metadata": {
        "id": "1ICyueLRaVhl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "def eval_model_without_mask(model, val_loader):\n",
        "    \n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    y_pred = torch.LongTensor()\n",
        "    y_score = torch.Tensor()\n",
        "    y_true = torch.LongTensor()\n",
        "    model.eval()\n",
        "    for x, y in val_loader:\n",
        "        y_hat = model(x)\n",
        "        y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
        "        y_hat = (y_hat > 0.5).int()\n",
        "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
        "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
        "\n",
        "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "    roc_auc = roc_auc_score(y_true, y_score, average='samples')\n",
        "\n",
        "    return p, r, f, roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UBUYPo9d1B7J",
      "metadata": {
        "id": "UBUYPo9d1B7J"
      },
      "outputs": [],
      "source": [
        "def train_with_mask(model, train_loader, val_loader, n_epochs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, masks,y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(x,masks)\n",
        "            loss = criterion(torch.squeeze(y_hat),y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "        p, r, f, roc_auc = eval_model_with_mask(model, val_loader)\n",
        "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'\n",
        "              .format(epoch+1, p, r, f, roc_auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rax7f_PbaFCi",
      "metadata": {
        "id": "Rax7f_PbaFCi"
      },
      "outputs": [],
      "source": [
        "def train_without_mask(model, train_loader, val_loader, n_epochs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x,y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(torch.squeeze(y_hat),y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
        "        p, r, f, roc_auc = eval_model_without_mask(model, val_loader)\n",
        "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'\n",
        "              .format(epoch+1, p, r, f, roc_auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YXXtIEFcSYqz",
      "metadata": {
        "id": "YXXtIEFcSYqz"
      },
      "source": [
        "## **3.1 MLP Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RInXvf9yTT7g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RInXvf9yTT7g",
        "outputId": "28579328-1a97-4e19-e2f5-d350096a58bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 43323\n",
            "Length of val dataset: 10831\n"
          ]
        }
      ],
      "source": [
        "dataset = CustomDataset(seqs, hfs)\n",
        "split = int(len(dataset)*0.8)\n",
        "\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, val_dataset = random_split(dataset, lengths)\n",
        "\n",
        "print(\"Length of train dataset:\", len(train_dataset))\n",
        "print(\"Length of val dataset:\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dHKBZJQTWB3",
      "metadata": {
        "id": "9dHKBZJQTWB3"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader = load_data(train_dataset, val_dataset, batch_size=32, collate_fn=Aggregator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-ykMCAzt4PHC",
      "metadata": {
        "id": "-ykMCAzt4PHC"
      },
      "outputs": [],
      "source": [
        "mlp = MLP(MAX_CODES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8gLgkLm14gwx",
      "metadata": {
        "id": "8gLgkLm14gwx"
      },
      "outputs": [],
      "source": [
        "criterion =  nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(),lr=0.001,weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AnTQ2mY84kuq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnTQ2mY84kuq",
        "outputId": "a9cea2dc-40cf-429f-f91e-731ef8d6e984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \t Training Loss: 0.325722\n",
            "Epoch: 1 \t Validation p: 0.75, r:0.24, f: 0.36, roc_auc: 0.92\n",
            "Epoch: 2 \t Training Loss: 0.262024\n",
            "Epoch: 2 \t Validation p: 0.79, r:0.36, f: 0.49, roc_auc: 0.93\n",
            "Epoch: 3 \t Training Loss: 0.242696\n",
            "Epoch: 3 \t Validation p: 0.82, r:0.44, f: 0.58, roc_auc: 0.93\n",
            "Epoch: 4 \t Training Loss: 0.229201\n",
            "Epoch: 4 \t Validation p: 0.84, r:0.51, f: 0.64, roc_auc: 0.94\n",
            "Epoch: 5 \t Training Loss: 0.217646\n",
            "Epoch: 5 \t Validation p: 0.85, r:0.57, f: 0.68, roc_auc: 0.94\n",
            "Epoch: 6 \t Training Loss: 0.213966\n",
            "Epoch: 6 \t Validation p: 0.86, r:0.62, f: 0.72, roc_auc: 0.94\n",
            "Epoch: 7 \t Training Loss: 0.206621\n",
            "Epoch: 7 \t Validation p: 0.86, r:0.65, f: 0.74, roc_auc: 0.94\n",
            "Epoch: 8 \t Training Loss: 0.209387\n",
            "Epoch: 8 \t Validation p: 0.88, r:0.67, f: 0.76, roc_auc: 0.95\n",
            "Epoch: 9 \t Training Loss: 0.215973\n",
            "Epoch: 9 \t Validation p: 0.88, r:0.69, f: 0.77, roc_auc: 0.95\n",
            "Epoch: 10 \t Training Loss: 0.216221\n",
            "Epoch: 10 \t Validation p: 0.88, r:0.71, f: 0.79, roc_auc: 0.95\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "train_without_mask(mlp, train_loader, val_loader, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UXrcoK91SDAN",
      "metadata": {
        "id": "UXrcoK91SDAN"
      },
      "source": [
        "## **3.2 GRU Model Training**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SDyiIztFRr7Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDyiIztFRr7Y",
        "outputId": "61a37e6a-ecab-44d4-c4a1-d52859ea355f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 43323\n",
            "Length of val dataset: 10831\n"
          ]
        }
      ],
      "source": [
        "dataset = CustomDataset(seqs, hfs)\n",
        "split = int(len(dataset)*0.8)\n",
        "\n",
        "lengths = [split, len(dataset) - split]\n",
        "train_dataset, val_dataset = random_split(dataset, lengths)\n",
        "\n",
        "print(\"Length of train dataset:\", len(train_dataset))\n",
        "print(\"Length of val dataset:\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fTVLeN0BJKjy",
      "metadata": {
        "id": "fTVLeN0BJKjy"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader = load_data(train_dataset, val_dataset, batch_size=32, collate_fn=MultiHotCollator(MAX_CODES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HiNgx1Gb0UQ0",
      "metadata": {
        "id": "HiNgx1Gb0UQ0"
      },
      "outputs": [],
      "source": [
        "gru = GRU(MAX_CODES, dp_out=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZwtcIomH0n6u",
      "metadata": {
        "id": "ZwtcIomH0n6u"
      },
      "outputs": [],
      "source": [
        "criterion =  nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(gru.parameters(),lr=0.001,weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZlWBv3lN1KMM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlWBv3lN1KMM",
        "outputId": "a7cc14c2-ec70-4f2c-8daf-fdc2086f0edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \t Training Loss: 0.112160\n",
            "Epoch: 1 \t Validation p: 0.99, r:0.89, f: 0.93, roc_auc: 0.99\n",
            "Epoch: 2 \t Training Loss: 0.038666\n",
            "Epoch: 2 \t Validation p: 0.99, r:0.90, f: 0.94, roc_auc: 0.99\n",
            "Epoch: 3 \t Training Loss: 0.020708\n",
            "Epoch: 3 \t Validation p: 0.98, r:0.91, f: 0.94, roc_auc: 0.99\n",
            "Epoch: 4 \t Training Loss: 0.011672\n",
            "Epoch: 4 \t Validation p: 0.99, r:0.89, f: 0.94, roc_auc: 0.99\n",
            "Epoch: 5 \t Training Loss: 0.006672\n",
            "Epoch: 5 \t Validation p: 0.97, r:0.91, f: 0.94, roc_auc: 0.99\n",
            "Epoch: 6 \t Training Loss: 0.006484\n",
            "Epoch: 6 \t Validation p: 0.99, r:0.91, f: 0.94, roc_auc: 0.98\n",
            "Epoch: 7 \t Training Loss: 0.005432\n",
            "Epoch: 7 \t Validation p: 0.98, r:0.91, f: 0.94, roc_auc: 0.98\n",
            "Epoch: 8 \t Training Loss: 0.004702\n",
            "Epoch: 8 \t Validation p: 0.96, r:0.91, f: 0.94, roc_auc: 0.99\n",
            "Epoch: 9 \t Training Loss: 0.003883\n",
            "Epoch: 9 \t Validation p: 0.96, r:0.91, f: 0.94, roc_auc: 0.99\n",
            "Epoch: 10 \t Training Loss: 0.003327\n",
            "Epoch: 10 \t Validation p: 0.96, r:0.91, f: 0.93, roc_auc: 0.99\n"
          ]
        }
      ],
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 10\n",
        "train_with_mask(gru, train_loader, val_loader, n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7d968b",
      "metadata": {
        "id": "3a7d968b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "illinois_payload": {
      "b64z": "",
      "nb_path": "release/HW5_MedGAN/HW5_MedGAN.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3 (Threads: 2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}